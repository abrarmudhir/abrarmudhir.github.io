{"0": {
    "doc": "üéì Education",
    "title": "Education ü¶úÔ∏èüéì",
    "content": "University College London, London, UK M.Eng. (Hons) in Computer Science (2:1) SEP 2004 ‚Äì JUN 2008 . | Emphasis on practical experience. Strong in software engineering, system design, and computational complexity. | Final year dissertation project: Investigation of correlated movement of exchange rates using neural networks. | . ",
    "url": "/education/#education-%EF%B8%8F",
    
    "relUrl": "/education/#education-Ô∏è"
  },"1": {
    "doc": "üéì Education",
    "title": "Certifications",
    "content": "Microsoft Azure Certifications APR 2022 ‚Äì PRESENT . Associate (4): . | Data Engineer Associate (DP-203) | Data Scientist Associate (DP-100) | Database Administrator Associate (DP-300) | AI Engineer Associate (AI-102) | . Fundamentals (8): . | Azure Data Fundamentals (DP-900) | AI Fundamentals (AI-900) | Azure Fundamentals (AZ-900) | Microsoft 365 Fundamentals (MS-900) | Dynamics 365 Fundamentals (CRM) (MB-910) | Dynamics 365 Fundamentals (ERP) (MB-920) | Power Platform Fundamentals (PL-900) | Security, Compliance, and Identity Fundamentals (SC-900) | . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/education/#certifications",
    
    "relUrl": "/education/#certifications"
  },"2": {
    "doc": "üéì Education",
    "title": "üéì Education",
    "content": "| ",
    "url": "/education/",
    
    "relUrl": "/education/"
  },"3": {
    "doc": "üï∏Ô∏è Experience",
    "title": "Experience ü¶úüï∏Ô∏è",
    "content": "illio Technology Ltd, London, UK Senior Data Engineer August 2023 ‚Äì July 2024 . Led the architecture and implementation of AWS-based ETL pipelines and Analytics platform, designing and developing data integrations and products. ACHIEVEMENTS: . | Technical Leadership &amp; Team Development - Built the data function from the ground up, hiring and developing a team that included a mid-level data engineer and a data scientist. Provided technical leadership, coaching, and mentorship. | Project: Serverless Data Pipelines - Implementing cloud-native ETL pipelines and a Data Analytics and Insights platform by leveraging key AWS services and Apache Airflow for Orchestration. | Project: Data Integrations and APIs - Building data integrations with market data providers and brokers. Building data APIs using a microservices architecture, deploying Docker and Kubernetes for container orchestration. Leveraging Fast API and Functions as a Service on AWS Lambda with API Gateway for efficient and modular API development. | Project: Analytics and Insights - Building an analytics and insights framework to facilitate faster time-to-market of Pythonic functions. Implementing analytics for Equities, FX, and Fund/ETF asset classes, focusing on financial markets and client multi-asset portfolios, including Cryptocurrencies. | . SKILLS: ‚Ä¢ Data Engineering on AWS (AWS Glue (ETL, Crawlers, Catalog, Workflow), Apache Airflow, Python, Pandas, SQL Alchemy, Fast API, Lambda, PostgreSQL, Data Lake - S3) ‚Ä¢ Full Stack (Python, React, Kotlin, Kubernetes) ‚Ä¢ DevOps (AWS CDK, GitLab) ‚Ä¢ Cloud (AWS (EC2, SNS, SQS, RDS, Redshift) . BlackRock, London, UK Vice President - Regional Team Lead of SFI Alpha Generation August 2021 ‚Äì February 2023 . Lead engineer for the investment model platform, focusing on team development and people management. Collaborated with the Fixed Income team to implement and back-test alpha models, and built front-office solutions for pre-trade, trade capture, and reporting. ACHIEVEMENTS: . | Technical Leadership &amp; Team Development - Mentored and developed a team of engineers, including 3 Senior Quant developers, fostering their career growth and technical skills. | BAU: Model Implementation - Worked with Quant Analysts to implement and enhance various models on the Pythonic alpha platform, including alpha, transaction cost, risk models, and optimizers. Managed cross-team implementations for Equities, Macro, Credit (structured), and Innovation, ensuring successful deployment across different asset classes. Enhanced the alpha framework with robust back-testing capabilities. Integrated INTEX Wrapper APIs for analysis of mortgage-backed assets. | Project: Aladdin Alpha Platform (Dynamic Flow) - Led the development of Aladdin Alpha Platform, emphasizing scalable design and reusability. Integrated with Snowflake for enhanced efficiency. | Project: Defence in Depth - Executed a comprehensive security upgrade for six major investment applications, redesigning components for secure architectures. Implemented secure APIs across diverse languages, including .NET, MATLAB, Perl, Python, and Java. | . SKILLS: ‚Ä¢ Leadership (Change Management, People Management, Project Management) ‚Ä¢ Practices (Agile, BDD, TDD) ‚Ä¢ Quant Stack (Python, Pandas, NumPy, Numba, Dask, Java, C#, MATLAB, SAS) ‚Ä¢ BI (Tableau, Microsoft Power BI) ‚Ä¢ Cloud (Microsoft Azure, Azure VM, Azure Functions) ‚Ä¢ Scheduling (Autosys) . Atlantis Solutions for ESA, Didcot, UK Full Stack Developer January 2020 ‚Äì January 2021 . Worked on a twelve-month contract with the European Space Agency (ESA), contributing to the Advanced Research in Telecommunications Systems Management Information System (ARTES MIS) project. ACHIEVEMENTS: . | Project: ARTES MIS - Developed a Java and Spring Boot backend API, along with a JSF front-end application, to manage 350+ research and development activities within the ARTES MIS project for the TIA Directorate. | BAU: Best Practices Rollout - Created secure, clean code on ESA cloud infrastructure, providing user training, and resolving technical issues. Migrated applications to a common environment for tools harmonization across TIA, contributing to knowledge exchange with team members and IT professionals. | . SKILLS: ‚Ä¢ Full Stack (Java, React, Spring Boot, Node.js, MariaDB) ‚Ä¢ Practices (Agile, BDD, TDD) ‚Ä¢ CMS (SharePoint) ‚Ä¢ BI (Microsoft Power BI) ‚Ä¢ Private Cloud (Private Network, Kubernetes, Docker, LDAP) . Golden Source Limited, London, UK Senior Consultant, Professional Services - CONTRACT March 2019 ‚Äì September 2019 . Worked as a Technical SME and Project Manager, handling budgeting, forecasting, stakeholder communication, and planning. Managed a team of five in migrating Golden Source to a cloud-hosted environment and led the upgrade of the legacy Security Master and Pricing product. ACHIEVEMENTS: . | Project: M&amp;G Prudential, Lite Security Master, and Pricing - Golden Source Upgrade - Delivered technical architecture advice and crafted functional and business requirements, technical solutions, and architecture documentation as a Technical SME and BA. | BAU: Best Practices Rollout - Successfully advocated for and implemented DevOps practices and tools, enhancing Continuous Integration/Delivery (CI/CD), and streamlining delivery and regression testing. | . SKILLS: ‚Ä¢ Leadership (Project Management, Microsoft Project) ‚Ä¢ Practices (Agile, JIRA) ‚Ä¢ GoldenSource EDM (Workflows, GSO/Mapping Designer, Connections) ‚Ä¢ Full Stack (Python, Java, Databases) ‚Ä¢ Integrations (Aladdin) ‚Ä¢ BI (Web Focus) . BlackRock, London, UK Associate, Senior Data Engineer of Aladdin Core Data November 2017 ‚Äì March 2019 . Worked as a Senior Data Engineer, served internal investment teams, and fulfilled data product needs. ACHIEVEMENTS: . | Project: Large Datasets Pipelines - Increased data processing efficiency through the development of PySpark and Scala data pipelines, effectively managing large datasets on the Hadoop Distributed File System (HDFS). | Project: Python Web Scrappers - Created a Java and Spring-based scraping framework, enabling rapid prototyping of new scrapers with reusable components. Enhanced data ingestion and crawling efficiency using Python and Java scrapers. | Project: Decommissioning of Data Management Platform (DMP) - Re-architected J2EE monolithic data platform into Python microservices for enhanced scalability. Developed flexible data models and pipelines, creating an internal Data Lake for efficient storage and accessibility of datasets from multiple sources. | Project: Decommissioning of MALT Refinery, Timeseries MIS - Revamped time-series data catalog management, replacing a C# desktop app with an advanced web application. Employed Angular for the front end and Java Spring Boot for the back end, achieving improved accessibility and usability. | . SKILLS: ‚Ä¢ Data Engineering (Data Modelling, Data Lake, Hadoop, Apache Spark) ‚Ä¢ Full Stack (Python, Java, C#, Spring Boot) ‚Ä¢ Practices (Agile, BDD, TDD) ‚Ä¢ DevOps (GIT, Sonar) ‚Ä¢ Scheduling (Autosys) . Golden Source Limited, London, UK Senior Technical Consultant, Professional Services July 2016 ‚Äì November 2017 . Worked as a senior technical consultant and SME and led GoldenSource implementations for clients. Led a 4-person team to validate intraday pricing rates, curves, and surfaces in a Reference and Market Data Project. Led a 4-month Fundamental Review of the Trading Book (FRTB) Proof of Concept (POC). ACHIEVEMENTS: . | Project: Siemens Financial Services, Market Data Solution Implementation - Built a reusable Murex connector and R analytics library with potential for sale to other clients. Utilized WebFOCUS (GS Insight) for BI reports, enhancing data accuracy and reporting efficiency. | Project: ICBC Standard Bank, Fundamental Review of Trading PoC - Integrated C libraries for scenario generation, enabling stress testing and output storage in the Golden Source Risk Master Data Model. Supported FRTB, showcasing advanced risk management. | . SKILLS: ‚Ä¢ Full Stack (Python, JEE, PSSQL (Oracle), R) ‚Ä¢ Golden Source EDM (Orchestrator, Workflows, Mapping Designer, Market Data Solution) . Rapid Addition Limited, London, UK Senior Developer, Trading Technology October 2014 ‚Äì July 2016 . Worked as a senior developer, implementing core functionalities for low-latency FIX engine libraries in both Java and C#. Contributed new full-stack ASIC reporting product, utilizing FIX protocol. Extended RA ShortCut ‚Äì FIX for BizTalk, enhancing performance and resolving bugs. ACHIEVEMENTS: . | Project: RA FIX Engine - Improved Java and C# FIX engine libraries with new API features, reduced error rates through code reviews, and increased test coverage. Developed trading solutions, FIX, and FAST engines, streamlining processes, and enhancing stakeholder satisfaction. | Project: RA ASIC Short Reporting Tool - Implemented a Full-stack solution for submitting short-selling reports to ASIC, enhancing efficiency through optimized FIX protocol utilization. Utilized ASP.NET and C# for the front end and MSSQL for the back end, ensuring seamless deployment on Azure Cloud, and reducing deployment time. | Project: RA ShortCut ‚Äì FIX for BizTalk - Enhanced core functionality, achieving measurable improvements in system performance and successfully resolving reported bugs. | . SKILLS: ‚Ä¢ Full Stack (Java, .NET (C#, ASP.NET) ‚Ä¢ FIX (Protocol/Engine, Certification) ‚Ä¢ Middleware (Microsoft BizTalk) ‚Ä¢ Cloud (Microsoft Azure) . BlackRock, London, UK Associate, Senior Quant Developer of Model-Based Fixed Income August 2010 ‚Äì July 2014 . Worked as a quant developer, implemented fixed-income investment models, optimizing efficiency, ensuring accurate data feeds, and managing the entire model lifecycle from development to production. ACHIEVEMENTS: . | Project: Common Alpha-Gen (CAGE) Platform - Developed core features to enable quant function encapsulation in SAS, R, and MATLAB. Executed the integration of task graphs with investment systems. | Project: Model Implementation - Collaborated on Model Implementation and Back-Testing with Quant analyst researchers. Implemented alpha, risk, and t-cost models in MATLAB, SAS, and R for a Fixed Income platform, improving model efficiency and accuracy. | Project: Data Management Platform - Engineered Data Management tools for efficient slicing and dicing of input data, delivering Tableau reports for front-office portfolio managers to enhance monthly attribution and investment dataset views. | . SKILLS: ‚Ä¢ Data Engineering (Informatica, J2SE/JEE, JavaScript) ‚Ä¢ Quant Stack (MATLAB, SAS, R, C#) ‚Ä¢ BI (PowerBI, Tableau, SAP Business Objects) ‚Ä¢ Scheduling (Autosys) . Client Knowledge Limited (now ICAP), London, UK Quantitative Developer, Managed Models May 2009 ‚Äì August 2010 . Worked as a quant developer and connectivity engineer, facilitating real-time market connectivity and high-frequency algorithmic trading. ACHIEVEMENTS: . | Project: Market Connectors - Designed and developed a low-latency framework to capture, receive, and replay real-time high-frequency data, reducing reliance on third-party market data systems. Developed adapters for CEP Engines enabling direct access to streaming market data using FIX technologies. Connected to various forex market data feeds and the Market News Dow Jones feed. | Project: Model Implementation - Collaborated with research analysts to implement quantitative models including Value at Risk (VaR) and FX trading algos in CEP engines (Progres Apama and Coral8). | . SKILLS: ‚Ä¢ Full Stack (Java, JavaScript, Progress Apama CEP) ‚Ä¢ FIX (QuickFix, Client Onboarding, Testing) ‚Ä¢ Data Engineering (Data Modelling, SQL) ‚Ä¢ BI (SAP Business Objects BI 4. X). British Telecom, Adastral Park Ipswich, UK Rich Client User Interface Designer July 2007 ‚Äì September 2007 . SKILLS: Full Stack (Java EE, JSPs, SIP Servlets, XML, HTML, CSS, JavaScript, AJAX, Web 2.0) . Sempra Energy, London, UK Financial Application Developer August 2006 ‚Äì October 2006 . SKILLS: Full Stack (Excel VBA, Java, XML processing, HTML, CSS, JavaScript) . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/experience/#experience-%EF%B8%8F",
    
    "relUrl": "/experience/#experience-Ô∏è"
  },"4": {
    "doc": "üï∏Ô∏è Experience",
    "title": "üï∏Ô∏è Experience",
    "content": "| ",
    "url": "/experience/",
    
    "relUrl": "/experience/"
  },"5": {
    "doc": "üëã Profile",
    "title": "Profile ü¶úüëã",
    "content": "ü§πüèø‚Äç‚ôÇÔ∏è Life‚Ä¢Long‚Ä¢Learner | üèÑ‚Äç‚ôÇÔ∏è Data‚Ä¢Products | üõ† Data‚Ä¢Engineering |üî¨ Data‚Ä¢Science . As a lifelong learner and versatile engineer in financial services, I mix humor with a serious passion for tech and the environment. I‚Äôm a people-first person who thrives on connecting and collaborating. Using my skills in algorithms, data wrangling, and project management, I create impactful solutions that benefit both people and the planet. Let‚Äôs save the world, one clever idea and genuine connection at a time! . ",
    "url": "/#profile-",
    
    "relUrl": "/#profile-"
  },"6": {
    "doc": "üëã Profile",
    "title": "Resume",
    "content": "üëá You can download my latest resume in PDF format using the following link: . Download CV (Last updated: 22-Aug-2024) . ",
    "url": "/#resume",
    
    "relUrl": "/#resume"
  },"7": {
    "doc": "üëã Profile",
    "title": "Contact me",
    "content": "Feel free to reach out via email: abrarmudhir@outlook.com. | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/#contact-me",
    
    "relUrl": "/#contact-me"
  },"8": {
    "doc": "üëã Profile",
    "title": "üëã Profile",
    "content": "| ",
    "url": "/",
    
    "relUrl": "/"
  },"9": {
    "doc": "ü§πüèø‚Äç‚ôÇÔ∏è Learning",
    "title": "Life ‚Ä¢ Long ‚Ä¢ Learning ü¶úü§πüèø‚Äç‚ôÇÔ∏è",
    "content": "Coming Soon . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/l3/#life--long--learning-%EF%B8%8F",
    
    "relUrl": "/l3/#life--long--learning-Ô∏è"
  },"10": {
    "doc": "ü§πüèø‚Äç‚ôÇÔ∏è Learning",
    "title": "ü§πüèø‚Äç‚ôÇÔ∏è Learning",
    "content": "| ",
    "url": "/l3/",
    
    "relUrl": "/l3/"
  },"11": {
    "doc": "üîó Organisations",
    "title": "Organisations ü¶úüîó",
    "content": "Pay.UK Jobs 21 August 2024 . Giving the UK choice in how it pays. About the Company . | Industry | Founded | Employees | CEO | Links | . | Financial Services | 2017 | 373 | David Pitt | linkedIn | org-chart | uk companies-house | . Pay.UK maintains and develops the UK retail payment systems and standards that are core to the economy being able to function on a day-to-day basis. From Bacs to Faster Payments and cheques ‚Äì we act as the single operator for all UK retail payments. We put the needs of consumers and businesses at the heart of everything we do, working in the public interest to ensure that the systems the country relies on for its banking transactions are safe, open, innovative and resilient. Our payment systems underpin the services that enable funds to be transferred between people and institutions. In 2022, the UK‚Äôs retail payment systems processed 11.1 billion transactions worth ¬£7.9 trillion through Bacs Direct Credit, Direct Debit, Faster Payments, and cheques, and our Current Account Switch Service has facilitated over 9 million switches since it‚Äôs launch in 2013. Every day, individuals and businesses use the services we provide to get their salaries, pay their bills and make online and mobile banking payments. Our vision for the future is to enable a vibrant economy, with Pay.UK delivering the best-in-class payment infrastructure and standards for the benefit of consumers and businesses nationwide. Read more Tech Stack . Python, DAX, R, M, VBA, SQL Stack Specialties . Payments Trafigura Jobs 20 August 2024 . Connecting vital resources to power and build the world. About the Company . | Industry | Founded | Employees | CEO | Links | . | Oil and Gas | 1993 | 12000 | Jeremy Weir | linkedIn | org-chart | uk companies-house | . Trafigura is a leading commodities group, owned by its employees and founded over 30 years ago. At the heart of global supply, Trafigura connects vital resources to power and build the world. We deploy infrastructure, market expertise and our worldwide logistics network to move oil and petroleum products, metals and minerals, gas and power from where they are produced to where they are needed, forming strong relationships that make supply chains more efficient, secure and sustainable. We invest in renewable energy projects and technologies to facilitate the transition to a low-carbon economy, including through H2Energy Europe and joint venture Nala Renewables. The Trafigura Group also comprises industrial assets and operating businesses including multi-metals producer Nyrstar, fuel storage and distribution company Puma Energy, and our Impala Terminals joint venture. The Group employs over 12,000 people, of which over 1,400 are shareholders and is active in 156 countries. At the heart of global supply, Trafigura connects vital resources to power and build the world. Through our Metals and Minerals, Oil &amp; Petroleum Products and Gas, Power and Renewables, commercial divisions, we use infrastructure, logistics and financing to connect producers and consumers, using our deep understanding of the markets we serve to make supply more efficient, secure and sustainable. We are accelerating our investments in renewable energy, including hydrogen, ammonia and other low-carbon energy technologies required for the transition to a low carbon future. We are committed to responsible business practices and we work with our stakeholders to improve environmental and social standards, bringing greater trust and transparency to global supply chains. A career at Trafigura offers a gateway to working on some of the most exciting challenges of a rapidly changing world ‚Äì from helping to optimise supply chains to developing infrastructure and new markets. In a culture that is founded on openness and energy, our people work as part of a multinational, globally connected team and thrive in a fast-paced environment where they can nurture and commercialise bold ideas. Everyone has a voice and is empowered to collaborate across geographies and disciplines to help shape our business and the wider world. We know the importance and value of diversity in our business and we invest in attracting, developing and retaining talent from all backgrounds. Founded in 1993, Trafigura is one of the largest independent employee-owned commodities groups in the world with over 12,000 people working across more than 60 offices. The Trafigura Group owns global multi-metals producer Nyrstar; fuel storage and distribution company Puma Energy; and joint ventures Impala Terminals, a port and logistics provider, and Nalo Renewables, investing in wind, solar and battery storage projects. Read more Tech Stack . SQL Server, Oracle, Java, AWS, S3, RDS, Lambda, Glue, Redshift, Change Data Capture (CDC) Specialties . Shipping and Chartering, Supply chain management, Oil and Petroleum products, Critical metals and minerals , Carbon management, Energy, Supply chain management, Power trading, Renewables, Commodity trading, and Logistics Reach PLC Jobs 20 August 2024 . Reach plc - The UK and Ireland's largest commercial news publisher. About the Company . | Industry | Founded | Employees | CEO | Links | . | Technology, Information and Media | 1832 | 2108 | David Higgerson | linkedIn | org-chart | uk companies-house | . Reach is the largest commercial publisher in the UK and Ireland. We own over 130 of the most trusted and popular national, regional and local media brands, with a combined print and digital monthly reach of 48m. With over 10 million registered customers, we are proud to be campaigners, champions and changemakers in our communities. We are Reach Plc, you might not have heard of us but we have probably met without you even realising it. We are home to the UK and Ireland‚Äôs most iconic digital platforms, magazines and newspapers. From the Mirror, Daily Express and OK!, to our regional titles such as the Liverpool Echo, BirminghamLive and the Manchester Evening News (plus lots more), our brands and the stories we cover are as varied as our people. We help all kinds of people share experiences through our stories because we believe this is what makes us human. Oh, and we should probably also mention that with a monthly readership of 47 million people, Reach is the largest commercial publisher in the UK. At Reach, not only will you feel better understood, you will also feel you understand other people better too. Read more Tech Stack . Redshift, ETL, AWS, CI/CD, OLAP, Kimball, Data Mart, Data Warehouse, Data Models, IAM, RBAC, Apache Airflow Specialties . Publishing GroundTruth AI Jobs 19 August 2024 . Revolutionise your Financial Crime Detection using AI. About the Company . | Industry | Founded | Employees | CEO | Links | . | IT Services and IT Consulting | 2024 | 10 | Matthew John BAZELEY | linkedIn | org-chart | uk companies-house | . At Groundtruth we build, explain and deploy AI solutions for financial crime detection. We help our clients understand and implement safe AI solutions to modernize their detection capabilities while remaining compliant to regulations. Groundtruth AI is a newly founded and growing start-up in 2024. We are a Google Cloud partner working to help major financial institutions transform the way they find and fight financial crime. Our founders have worked with Google for years and were key figures in shaping and building Google‚Äôs latest Cloud product targeting Anti-Money Laundering. We exist to develop and deploy technologies that make a measurable difference in tackling financial crime. The billions of dollars stolen and laundered each year mask untold human suffering which we can help prevent. Read more Tech Stack . SQL, python, rust, typescript, bigquery, apache ibis, sqlglot, DBT, Google Cloud Platform, AML AI Specialties . Financial Crime, AML, Anti Money Laundering, Compliance, AI, Machine Learning, and Analytics Applied Data Science Partners Jobs 16 August 2024 . Predict, optimise and automate your business with our end-to-end data science solutions driving measurable value. About the Company . | Industry | Founded | Employees | CEO | Links | . | IT Services and IT Consulting | 2016 | 50 | David Foster | linkedIn | org-chart | uk companies-house | . Applied Data Science Partners (ADSP) is an innovative consultancy dedicated to delivering value through the application of data science and AI. Founded in 2016, ADSP is a consultancy that provides businesses with world-class data science and AI solutions that deliver long-term value. We are a team of data engineers, scientists and architects who understand what it takes to meet this objective, every time. Every one of our projects is bespoke, but there are some core themes that run throughout our work. We favour a highly communicative approach - we take the time to meet with your team and establish the optimal way to utilise the data you are collecting. We also value transparency in our models - our data scientists know how to build state-of-the-art, interpretable models that predict, optimise and provide actionable recommendations. Lastly, we love automation - our highly skilled data engineers know the best way to deploy and scale the solution so that your business can start feeling the benefits of the project right away. Above all, our clients value our ability to transfer knowledge of the solution to internal stakeholders, both from a technical and non-technical perspective. We do this by spending time on-site with your team to walk through the deliverables in person. Our goal is to build solutions that feel part of the everyday running of your business and measurably contribute to its success. We care that the services that we provide stand the test of time. By engaging with us you can expect the highest quality of service and delivery on every project. Through our combined experience, we have developed a best-practice approach to developing AI technology, ensuring our clients are able to take advantage of the huge opportunities offered by the application of machine learning and data science. If you‚Äôd like to know more about any of our services or previous projects, please do reach out and we‚Äôd be happy to discuss further. Read more Tech Stack . Python, SQL, AWS, Azure, Git Specialties . Data Science, Analytics, Machine Learning, Consultancy, Deep Learning, Web Analytics, Big Data, AI, ETL, Data Warehouse, and Data Scientists Arenko Group Jobs 14 August 2024 . Arenko is a market leading technology provider enabling the clean energy transition. About the Company . | Industry | Founded | Employees | CEO | Links | . | Services for Renewable Energy | 2014 | 200 | Rupert Newland | linkedIn | org-chart | uk companies-house | . Our vision is a zero carbon grid worldwide. As we move to the high-renewables and low carbon era, electricity storage is transforming the way the energy industry operates. The energy industry is fast becoming a digital and multidisciplinary sector that provides a fundamental service for modern society, but these needs must be delivered in a socially responsible way. Arenko is using new technology to add flexibility to the grid and secure supply in this fast-changing industry, offering a huge variety of opportunities for the future. At Arenko we are strongly committed to our mission of building a sustainable future by enabling a zero-carbon grid worldwide. Energy storage has a crucial role to play in the energy transition, and our technology enables the transformation of energy systems. We have committed a Sustainability Strategy. Arenko‚Äôs market-leading software platform uses the power of automation and machine learning to identify and unlock the value of batteries and renewables. Arenko‚Äôs technology optimises the technical and commercial performance of flexible assets in real time. It‚Äôs designed by a team of data science and market experts to maximise the availability and profitability of energy storage and generation in order to accelerate the transition to a fully decarbonised power system. Arenko was founded in 2014 to become the dominant player in energy. Since then, we have built a world class team. Arenko is growing rapidly in the emerging energy storage sector and has been operating live assets since mid-2016. If this makes you buzz with excitement then get on board and apply. At Arenko we value motivated, flexible people who are team players and willing to change the status quo. We want every employee to feel valued, comfortable and able to be their own free self at work. Together, we are committed to building a diverse and inclusive culture that encourages, supports and empowers the authentic voices of all our employees. All qualified applicants will receive consideration for employment without regard to race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age or any other aspect that makes you unique. We‚Äôd love to hear from you. Read more Tech Stack . Python, S3, Athena, Prefect, Pulsar, Cassandra, Postgres, AWS, Terraform, GitLab Specialties . Automation, Energy, Renewable Energy Pemberton Asset Management Jobs 13 August 2024 . Leading Alternative Credit Strategies. About the Company . | Industry | Founded | Employees | CEO | Links | . | Financial Services | 2011 | 200 | Symon Roderick DRAKE-BROCKMAN | linkedIn | org-chart | uk companies-house | . Pemberton Asset Management is a leading European private credit manager, distinguished by its innovative approach, superior credit analysis, and extensive network of local offices across Europe. The firm has evolved from its origins in direct lending to a diversified, multi-strategy private credit platform that supports investors in achieving their objectives. Backed by Legal &amp; General, one of Europe‚Äôs largest insurers, Pemberton offers a range of financing solutions for borrowers and investment opportunities for institutional investors. Pemberton combines asset management with banking expertise, allowing it to originate, select, and manage diverse credit exposures effectively through its on-the-ground offices. This network makes Pemberton an attractive partner for institutional investors seeking better yields and enhanced downside protection compared to liquid credit instruments. With a global investor base that includes insurance companies, pension funds, sovereign wealth funds, and family offices, Pemberton‚Äôs strategies have garnered long-term partnerships and significant investments. As of June 2024, Pemberton manages USD $22 billion in assets under management (AuM) and employs over 190 staff globally. The firm is also a leader in responsible investing, with a strong focus on talent recruitment, development, and workforce diversity. In 2021, Pemberton published a ‚ÄúReview and Outlook of European Direct Lending‚Äù in collaboration with Sa√Ød Business School at the University of Oxford, supported by proprietary data and legal insights from Latham &amp; Watkins, underscoring its commitment to transparency and thought leadership in the industry. Read more Tech Stack . Python Specialties . European Private Debt, Direct Lending, Corporate Loans, Credit, Working Capital Finance, NAV Financing, Risk Sharing Transactions, and CLOs Tokio Marine Jobs 09 August 2024 . Tokio Marine HCC is a member of the Tokio Marine Group of Companies. About the Company . | Industry | Founded | Employees | CEO | Links | . | Insurance | 2002 | 43870 | Satoru Komiya | linkedIn | org-chart | uk companies-house | . Tokio Marine HCC is a leading specialty insurance group conducting business in approximately 180 countries and underwriting more than 100 classes of specialty insurance. Headquartered in Houston, Texas, the company is comprised of highly entrepreneurial teams equipped to underwrite special situations, companies and individuals, acting independently to deliver effective solutions. Our products and capabilities set the standard for the industry, as many of our approximately 4,300 employees are industry-leading experts. Tokio Marine HCC is part of Tokio Marine, a premier global company with a market cap of approximately $61 billion. Tokio Marine Holdings, Inc. engages in the non-life and life insurance, and financial and general businesses in Japan and internationally. It operates through four segments: Domestic Non-Life Insurance Business, Domestic Life Insurance Business, International Insurance Business, and Financial and Other Businesses. The company provides fire and allied lines, hull and cargo, health, personal accident, automobile, and other insurance products, as well as asset management services. It also offers investment advisory, investment trust, staffing, facility management, and nursing care services. The company was formerly known as Millea Holdings, Inc. and changed its name to Tokio Marine Holdings, Inc. in 2008. The company was incorporated in 2002 and is headquartered in Tokyo, Japan . Read more Tech Stack . AWS, C#, .NET, SQL, Python, FastAPI, Flask, HTMX, React, Angular, Snowflake, Terraform Specialties . Accident and Health, Directors and Officers, Energy, International Credit and Political Risk, Liability, Marine, Professional Indemnity, Specialty, Surety and Bonds, Treaty Reinsurance, UK Trade Credit, Delegated Property , Financial Lines, Open Market Property, Marine Liability, and Marine Cargo Solomonic Ltd Jobs 08 August 2024 . Data powered litigation intelligence. About the Company . | Industry | Founded | Employees | CEO | Links | . | Legal Services | 2017 | 11-50 employees | Edward Bird | linkedIn | org-chart | uk companies-house | . The Solomonic platform is the solution for accurate, timely data and analytics in the UK litigation market. Don‚Äôt just be on top of the latest developments, connect the dots and practice at the cutting edge. Solomonic is an award-winning and intuitive litigation analytics platform. Our product drives actionable intelligence that transforms the way litigation decisions are made and empowers professionals to operate at the cutting edge of their sector. Founded on analytical rigour, data integrity and innovation in our product and business approach, we are on a mission to change the way litigation decisions are made. This, combined with extensive legal sector expertise, has cemented our position as a market leader, trusted by world leading businesses and law firms. As people, we value collaboration and community - focusing on growing our business in a way that reflects our high level of customer engagement and celebrates the value each team member brings to the product and the business. Read more Tech Stack . Software engineer, Full-stack, Typescript, Serverless, Node.js, Big data, Web scraping, React, Tailwind, Legal tech, Product, AWS, MongoDB, Terraform, Cypress, TDD, APIs Specialties . Litigation Analytics, Litigation Data, Commercial Litigation, and Litigation Intelligence MongoDB Jobs 05 August 2024 . A developer data platform for developers to do their best work. About the Company . | Industry | Founded | Employees | CEO | Links | . | Software Development | 2007 | 5,001-10,000 employees | Dev Ittycheria | linkedIn | org-chart | uk companies-house | . Headquartered in New York, MongoDB‚Äôs mission is to empower innovators to create, transform, and disrupt industries by unleashing the power of software and data. Built by developers, for developers, our developer data platform is a database with an integrated set of related services that allow development teams to address the growing requirements for today‚Äôs wide variety of modern applications, all in a unified and consistent user experience. MongoDB has tens of thousands of customers in over 100 countries. The MongoDB database platform has been downloaded hundreds of millions of times since 2007, and there have been millions of builders trained through MongoDB University courses. To learn more, visit mongodb.com. MongoDB, Inc., together with its subsidiaries, provides general purpose database platform worldwide. The company provides MongoDB Atlas, a hosted multi-cloud database-as-a-service solution; MongoDB Enterprise Advanced, a commercial database server for enterprise customers to run in the cloud, on-premises, or in a hybrid environment; and Community Server, a free-to-download version of its database, which includes the functionality that developers need to get started with MongoDB. It offers professional services comprising consulting and training. The company was formerly known as 10gen, Inc. and changed its name to MongoDB, Inc. in August 2013. MongoDB, Inc. was incorporated in 2007 and is headquartered in New York, New York. Read more Tech Stack . MongoDB, Oracle, MS SQL Server, PostgreSQL, MySQL, ETL, Apache Kafka, Java, C++, C#, Python, Node.js (JavaScript), Ruby, Perl, Scala, Go, GenAI, OpenAI API Specialties . open source, databases, mongodb, and software developer sea.dev Jobs 31 July 2024 . sea.dev is the developer and provider of certain technology that can be used by its Partners and their users to structure data for Large Language Model usage. About the Company . | Industry | Founded | Employees | CEO | Links | . | Software Development | | 2-10 employees | | linkedIn | org-chart | uk companies-house | . We are building technology to enable Fintechs to flexibly embed LLM capabilities into their workflows and products. The founding team has worked at world-leading financial and research institutions, and brings together decades of experience in data technology, graphs, and finance. We have extensive prior experience building data teams and launching data products from scratch. Our culture is founded on trust, pragmatism, and velocity. We have a huge opportunity in front of us and are looking for exceptional people to join us. Read more Tech Stack . React, TypeScript, Python, Render, Github, Axiom, Twilio, AWS, OpenAI, Anthropic, Supabase, Neo4j, Posthog Specialties . Fintech, AI Infra, SaaS Illio Jobs 14 August 2023 . Wealth Insights that make sense to everyone About the Company . | Industry | Founded | Employees | CEO | Links | . | Financial Services | | 11-50 employees | | linkedIn | org-chart | uk companies-house | . We aim to bring simplicity, efficiency and transparency to the wealth industry. Traditionally, analyzing wealth is a complex process which doesn‚Äôt help advisor productivity. Furthermore, explaining wealth is often jargon intense which doesn‚Äôt help stakeholders‚Äô understanding of what they own. Our modular wealth platform is designed to support wealth firms, online platforms, family offices, asset or fund managers with time saving analytics, user friendly visualizations and personalized portfolio Insights. Read more Tech Stack . AWS, Kotlin, Python Specialties . Fintech, Wealth Management, Analytics . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/organisations/#organisations-",
    
    "relUrl": "/organisations/#organisations-"
  },"12": {
    "doc": "üîó Organisations",
    "title": "üîó Organisations",
    "content": "| ",
    "url": "/organisations/",
    
    "relUrl": "/organisations/"
  },"13": {
    "doc": "üõ†Ô∏è Projects",
    "title": "Projects ü¶úüõ†Ô∏è",
    "content": "Coming Soon . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/projects/#projects-%EF%B8%8F",
    
    "relUrl": "/projects/#projects-Ô∏è"
  },"14": {
    "doc": "üõ†Ô∏è Projects",
    "title": "üõ†Ô∏è Projects",
    "content": "| ",
    "url": "/projects/",
    
    "relUrl": "/projects/"
  },"15": {
    "doc": "üó£Ô∏è Q & A",
    "title": "Q &amp; A ü¶úüó£Ô∏è",
    "content": "All Topics Data Soft Skills AWS Python Web Testing SDLC Design Patterns Softies ‚ú® . Soft Skills . How do you ensure that your team stays updated with the latest technology trends and skills? . Question . How do you ensure that your team stays updated with the latest technology trends and skills? Answer . I prioritise continuous learning and development within my team by encouraging participation in workshops, certifications, and online courses. I also schedule regular knowledge-sharing sessions where team members present new tools, technologies, or methodologies they‚Äôve explored. Additionally, I foster a culture of experimentation, allowing the team to pilot new technologies on smaller projects before scaling them up. Date Added: 21 August 2024 . How would you handle a situation where the data engineering team is resistant to adopting a new technology? . Question . How would you handle a situation where the data engineering team is resistant to adopting a new technology? Answer . I would start by understanding the root cause of the resistance, which could range from a lack of familiarity with the technology to concerns about its impact on existing workflows. I would then organize training sessions and workshops to address knowledge gaps and demonstrate the benefits of the new technology through proof-of-concept projects. By involving the team in the decision-making process and addressing their concerns directly, I can help ease the transition and build their confidence in the new technology. Date Added: 21 August 2024 . Imagine you are leading a cloud migration project, and halfway through, the budget gets cut by 30%. How would you adjust your approach? . Question . Imagine you are leading a cloud migration project, and halfway through, the budget gets cut by 30%. How would you adjust your approach? Answer . With a reduced budget, I would re-evaluate the scope of the project, focusing on the most critical components that deliver the highest business value. I would consider a phased approach, prioritizing core systems for migration while deferring less critical ones. Additionally, I would explore cost-saving measures such as using more cost-effective cloud services or optimizing existing resources. Clear communication with stakeholders is crucial to align expectations and secure their buy-in for the revised plan. Date Added: 21 August 2024 . How would you manage a situation where a key project is falling behind schedule? . Question . How would you manage a situation where a key project is falling behind schedule? Answer . First, I would assess the root causes of the delay by conducting a thorough review of the project‚Äôs progress, including resource allocation, task dependencies, and any unforeseen challenges. I would then re-prioritize tasks, possibly reassigning resources or adjusting the project scope to focus on the most critical deliverables. Communication is key, so I would keep stakeholders informed about the situation and the revised plan to manage expectations. Implementing daily stand-ups and frequent check-ins can help monitor progress more closely and ensure the team stays on track. Date Added: 21 August 2024 . How do you approach building and developing a high-performing data engineering team? . Question . How do you approach building and developing a high-performing data engineering team? Answer . I focus on hiring individuals with both technical proficiency and a collaborative mindset. Once the team is in place, I invest in their continuous development through mentorship, training programs, and regular feedback sessions. I also promote a culture of ownership, where team members are encouraged to take responsibility for their projects, which fosters innovation and accountability. Regular team-building activities help in aligning the team‚Äôs goals and improving collaboration. Date Added: 21 August 2024 . Can you describe a time when you led a data migration project? . Question . Can you describe a time when you led a data migration project? What were the challenges, and how did you overcome them? Answer . At BlackRock, I led a data migration project involving the transition of a legacy investment model platform to a cloud-based solution. The challenges included dealing with complex dependencies, ensuring data integrity, and maintaining performance standards. To overcome these, I employed a phased migration approach, utilized cloud-native tools for data validation, and set up parallel processing to verify results against the legacy system. Regular communication with stakeholders and robust testing protocols ensured a smooth transition. Date Added: 21 August 2024 . Describe a situation where you had to manage conflicting priorities. Question . Describe a situation where you had to manage conflicting priorities. How did you handle it? Answer . During my time at Illio Technology, we had to simultaneously develop a new analytics platform while maintaining an existing data pipeline. The key was to establish clear communication channels with stakeholders to prioritise tasks based on business impact. I used Agile methodologies to manage workloads, ensuring that the team focused on high-priority tasks during sprints while allocating buffer time for urgent maintenance work. This approach allowed us to meet critical deadlines without compromising on the quality of ongoing projects. Date Added: 21 August 2024 . Can you walk us through your CV, focusing on the technologies you have worked with and the projects you have led? . Question . Can you walk us through your CV, focusing on the technologies you have worked with and the projects you have led? Answer . Certainly. In my most recent role at Illio Technology Ltd, I led the architecture and implementation of AWS-based ETL pipelines and analytics platforms. This involved using technologies such as AWS Glue, Apache Airflow, Python, and PostgreSQL. One key project was developing serverless data pipelines, leveraging AWS Lambda and API Gateway for efficient API development. At BlackRock, as Vice President, I led a team to enhance the Aladdin Alpha Platform. We integrated Snowflake for better data efficiency and implemented secure APIs across .NET, MATLAB, Perl, Python, and Java. I have extensive experience with relational databases like Oracle and MS SQL Server, and NoSQL databases like MongoDB. Additionally, I‚Äôve worked with distributed streaming platforms such as Apache Kafka and ETL tools. Earlier in my career at Golden Source Limited, I managed the migration of their Security Master and Pricing product to a cloud-hosted environment and advocated for DevOps practices to improve CI/CD processes. Throughout my career, I‚Äôve consistently used technologies such as Java, Python, React, Kubernetes, and various cloud platforms like AWS and Azure. Date Added: 06 August 2024 . Tell me about yourself . Question . How would you summarise your professional background and experience? Answer . I am a Senior Data Engineer with a strong background in data engineering, application development, and project management. Currently, I am leading the data engineering team at illio Technology Ltd, where I design and implement AWS-based ETL pipelines and analytics platforms. My experience includes significant roles at BlackRock, where I led the development of investment model platforms and implemented robust solutions for fixed income models. I have a diverse skill set, including expertise in Python, AWS, and full-stack development. My career has involved developing data integrations, building APIs, and working on cloud-native solutions. I also have a solid foundation in leadership and team development, having mentored teams and driven technical excellence across various projects. In addition to my technical skills, I have a proven track record in improving processes and ensuring successful project outcomes. My ability to adapt to new challenges and drive innovation has been a key factor in my career success. Date Added: 03 August 2024 . Ability to own problems, as well as work well in a team . Question . Can you describe your ability to own problems and work effectively in a team? Answer . Owning problems and working well in a team are essential soft skills that contribute significantly to effective project delivery and team dynamics. Here‚Äôs how I approach these aspects: Owning Problems: . | Proactive Approach: I take a proactive stance in identifying and addressing issues before they escalate. By anticipating potential challenges, I can address them early and prevent them from impacting the project‚Äôs progress. | Accountability: I hold myself accountable for my tasks and responsibilities. If a problem arises, I ensure that I take ownership of finding a solution, rather than shifting blame or deflecting responsibility. | Problem-Solving Mindset: I adopt a problem-solving mindset by analyzing the root causes of issues and exploring multiple solutions. This involves researching, brainstorming, and iterating until an effective resolution is found. | Continuous Improvement: I regularly seek feedback and reflect on my approach to problem-solving to continuously improve. By learning from each experience, I enhance my skills and contribute to better outcomes in future projects. | . Working Well in a Team: . | Effective Communication: I prioritise clear and open communication with team members. This involves actively listening, sharing information transparently, and providing constructive feedback. Good communication helps in aligning goals, setting expectations, and resolving conflicts. | Collaboration: I thrive in collaborative environments where team members support each other and work towards common goals. I contribute my expertise and also leverage the diverse skills and perspectives of my colleagues to achieve the best results. | Empathy and Support: I practice empathy by understanding and considering the perspectives and challenges of my teammates. Providing support and encouragement fosters a positive team atmosphere and enhances overall productivity. | Flexibility and Adaptability: I am flexible and adaptable in my approach to teamwork. This means being open to different working styles, accommodating changes, and being willing to adjust my role or responsibilities as needed to support the team‚Äôs success. | . By combining these approaches to owning problems and working effectively in a team, I contribute to a collaborative and solution-oriented work environment, leading to successful project outcomes and a positive team experience. Date Added: 02 August 2024 . What you know about US, what you could bring to OUR team . Question . What do you know about US, what could you bring to US, and why do you want to join US based on what you have researched? Answer . My Understanding: . You are a leading global firm with a strong reputation for providing a broad range of insurance products and services. Known for its innovation and commitment to excellence, You operate in various sectors including specialty insurance, property and casualty, and professional lines. The company focuses on delivering tailored solutions and leveraging cutting-edge technology to address the evolving needs of its clients. What I Could Bring to YOUR Team: . | Innovative Problem-Solving: With my experience in data engineering and software development, I bring a strong ability to solve complex problems and implement innovative solutions. My background includes developing cloud-native applications, designing scalable data pipelines, and leveraging modern technologies to drive business value. | Technical Expertise: I have hands-on experience with a variety of technologies relevant to your innovation goals, such as AWS services, Python, and container orchestration tools like Docker and Kubernetes. My skills in these areas can contribute to enhancing Your‚Äôs technology stack and improving operational efficiencies. | Collaboration and Leadership: I have a proven track record of working effectively in team environments and leading technical projects. My ability to mentor and collaborate with cross-functional teams will support the Innovation team‚Äôs efforts in driving transformative projects and fostering a culture of innovation. | Data-Driven Insights: My experience in building analytics frameworks and processing large datasets can be valuable in deriving actionable insights from data, which can drive decision-making and strategic planning within Your. | . Why I Want to Join YOU: . | Commitment to Innovation: Your‚Äôs emphasis on leveraging technology and innovative solutions aligns with my passion for using technology to solve real-world problems and drive industry advancements. The company‚Äôs forward-thinking approach is an exciting environment where I can contribute and grow professionally. | Reputation and Values: Your‚Äôs strong reputation for integrity, customer focus, and excellence resonates with my personal and professional values. Joining an organization that prioritizes these values is important to me, as it ensures that I am part of a team that strives for the highest standards in everything it does. | Career Development: Your offers a dynamic and challenging work environment that fosters continuous learning and development. I am eager to be part of a company that invests in its employees and provides opportunities for growth and advancement. | . My research into Your has shown that it is an organization at the forefront of industry innovation, and I am enthusiastic about the prospect of contributing to its success. I am confident that my skills and experiences make me a strong fit for Your‚Äôs Innovation team, and I am excited about the opportunity to be part of a company that values innovation and excellence. Date Added: 02 August 2024 . Techies üë®‚Äçüíª . Data . How would you leverage TOGAF to align IT architecture with business strategy during a major system overhaul? . Question . How would you leverage TOGAF to align IT architecture with business strategy during a major system overhaul? Answer . TOGAF (The Open Group Architecture Framework) provides a comprehensive approach to aligning IT architecture with business strategy, especially during a major system overhaul. Here‚Äôs how I would leverage TOGAF: . | Preliminary Phase: . | Establish Architecture Framework: I would start by defining the architecture vision and setting up the architecture governance framework. This phase involves understanding the business goals, drivers, and stakeholders, which is crucial for ensuring alignment with the business strategy. | . | Architecture Vision: . | Develop Architecture Vision: Using TOGAF‚Äôs guidelines, I would articulate the architecture vision, ensuring it encapsulates the business strategy, scope, and high-level architecture. This step involves stakeholder engagement to ensure buy-in and alignment. | . | Business Architecture: . | Model Business Architecture: I would develop a detailed business architecture model that includes business processes, organizational structure, and business goals. This model serves as a blueprint to ensure that the IT architecture supports the business strategy and operational objectives. | . | Information Systems Architecture: . | Design Data and Application Architectures: In this phase, I would design the data architecture and application architecture. TOGAF provides best practices for ensuring that the architecture is modular, scalable, and aligned with the business requirements identified earlier. | . | Technology Architecture: . | Select Appropriate Technologies: The next step involves defining the technology architecture. I would choose technologies that not only meet the current needs but also align with future business strategies. TOGAF‚Äôs reference models and standards guide the selection of interoperable and future-proof technologies. | . | Opportunities and Solutions: . | Identify Solutions and Gaps: I would use TOGAF to identify potential solutions and gaps between the current and target architectures. This phase ensures that the architecture design aligns with the business goals and addresses any shortcomings that might hinder business operations. | . | Migration Planning: . | Develop Roadmap: TOGAF helps in creating a detailed roadmap for migration, which is essential during a system overhaul. This roadmap outlines the steps, timelines, and resources needed, ensuring minimal disruption to business operations. | . | Implementation Governance: . | Ensure Compliance and Alignment: Throughout the implementation, I would use TOGAF‚Äôs architecture governance model to ensure that the project remains aligned with the business strategy, with continuous monitoring and adjustment as necessary. | . | Architecture Change Management: . | Adapt and Evolve: Post-implementation, TOGAF‚Äôs change management guidelines help in adapting the architecture as the business strategy evolves. This ensures long-term alignment and scalability of the IT systems. | . | . Outcome: By following TOGAF‚Äôs structured approach, I would ensure that the IT architecture not only supports the current business strategy but also remains flexible enough to adapt to future business needs, thereby facilitating a smooth system overhaul aligned with strategic business objectives. No script field found. Date Added: 21 August 2024 . How do you approach the challenge of maintaining both legacy systems and modern cloud-based systems? . Question . How do you approach the challenge of maintaining both legacy systems and modern cloud-based systems? Answer . | Hybrid Infrastructure: I would establish a hybrid infrastructure that allows both systems to coexist, with a clear strategy for integrating legacy systems with modern cloud services. | Incremental Migration: Gradually migrate components from legacy systems to the cloud. Start with non-critical workloads and build confidence before migrating more critical systems. | Middleware: Use middleware or integration platforms (like Mulesoft or Azure Logic Apps) to bridge the gap between legacy systems and cloud applications, ensuring smooth data flow and communication. | Data Synchronization: Implement data synchronization processes, ensuring that data remains consistent and up-to-date across both environments. | Staff Training: Invest in training and development for team members to handle both legacy and cloud systems effectively. | . No script field found. Date Added: 21 August 2024 . What strategies would you employ to ensure data quality and consistency across distributed systems? . Question . What strategies would you employ to ensure data quality and consistency across distributed systems? Answer . | Data Validation Rules: Implement validation rules at the data ingestion stage to ensure that incoming data meets predefined quality criteria. | Data Governance: Establish a data governance framework that includes data quality metrics, stewardship roles, and responsibilities. This also includes using tools like Apache Atlas for metadata management. | Master Data Management (MDM): Implement MDM practices to create a single source of truth for key business entities, ensuring data consistency across all systems. | Automated Testing: Utilize unit tests, integration tests, and data profiling tools like Great Expectations to detect data anomalies and inconsistencies early in the pipeline. | Monitoring and Alerting: Continuous monitoring using tools like Grafana or AWS CloudWatch to detect issues in real-time and set up alerts to handle them proactively. | . No script field found. Date Added: 21 August 2024 . How would you design a data pipeline for a real-time analytics application? . Question . How would you design a data pipeline for a real-time analytics application? Answer . Designing a real-time data pipeline involves several components: . | Data Ingestion: For real-time ingestion, I would use a streaming platform like Apache Kafka or AWS Kinesis to collect and transmit data to processing systems. | Data Processing: Implement stream processing using frameworks like Apache Flink or Apache Spark Streaming to transform and aggregate the data in real time. | Data Storage: Depending on the use case, I might choose a fast, scalable storage solution like Amazon S3 for raw data or Amazon Redshift for structured data that needs to be queried. | Analytics: For analytics, tools like AWS QuickSight, Power BI, or Tableau can be used to visualize data. In cases where immediate insights are necessary, setting up dashboards with auto-refresh capabilities could be crucial. | Monitoring and Alerts: Implementing monitoring using AWS CloudWatch or Prometheus for pipeline health and setting up alerts for any anomalies. | . No script field found. Date Added: 21 August 2024 . Can you describe the process you would follow to migrate an on-premises database to the cloud? . Question . Can you describe the process you would follow to migrate an on-premises database to the cloud? Answer . Migrating an on-premises database to the cloud involves several steps: . | Assessment and Planning:: First, evaluate the existing on-premises databases, including their size, performance characteristics, and dependencies. This includes understanding the data model, the volume of data, and the workload patterns. | Choosing the Cloud Platform and Services: Based on the assessment, select the appropriate cloud services (e.g., Azure SQL Database, Azure Data Lake, etc.) that match the performance and scalability needs. | Data Migration Strategy: Decide on a migration strategy, which could be a lift-and-shift approach (moving the database as-is), or a more sophisticated re-architecture to take advantage of cloud-native services. | Data Transfer: Use tools like Azure Database Migration Service (DMS) for the actual data transfer. During this step, consider using BACPAC files for SQL Server databases or tools like SSIS and Data Factory for more complex migrations. | Testing: Before making the switch, perform extensive testing on the cloud database to ensure data integrity and performance. This includes running your ETL jobs, checking stored procedures, and validating reports. | Cutover and Monitoring: Plan the final cutover, usually during a low-traffic period. After the migration, set up monitoring to ensure everything is running smoothly and perform any optimizations required. | . No script field found. Date Added: 21 August 2024 . AWS . Name some AWS components and services that provide compute resources . Question . Name some AWS components and services that provide compute resources, for instance ways to run VMs, containers or serverless? Answer . AWS offers a variety of services and components to provide compute resources, allowing users to run virtual machines, containers, and serverless applications. Here are some of the key services: . | Amazon EC2 (Elastic Compute Cloud): Provides resizable compute capacity in the cloud. Users can launch virtual machines, known as instances, with different configurations to meet their needs. EC2 supports various operating systems and instance types for diverse use cases. # Example: Launching an EC2 instance aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name MyKeyPair . | AWS Lambda: Offers serverless compute capabilities, allowing users to run code in response to events without provisioning or managing servers. Lambda functions can be triggered by AWS services like S3, DynamoDB, or API Gateway. # Example: Creating a Lambda function aws lambda create-function --function-name MyFunction --runtime python3.8 --role arn:aws:iam::123456789012:role/service-role/MyRole --handler lambda_function.lambda_handler --zip-file fileb://function.zip . | Amazon ECS (Elastic Container Service): A container orchestration service that supports Docker containers. ECS allows users to run and manage containers on a cluster of EC2 instances, integrating with other AWS services for scaling and management. # Example: Creating an ECS cluster aws ecs create-cluster --cluster-name MyCluster . | Amazon EKS (Elastic Kubernetes Service): A managed Kubernetes service that simplifies running Kubernetes clusters on AWS. EKS handles the setup, scaling, and management of Kubernetes, making it easier to deploy and manage containerized applications. # Example: Creating an EKS cluster aws eks create-cluster --name MyCluster --role-arn arn:aws:iam::123456789012:role/EKSRole --resources-vpc-config subnetIds=subnet-12345678,subnet-87654321 . | AWS Fargate: A serverless compute engine for containers that works with both ECS and EKS. Fargate allows users to run containers without managing the underlying EC2 instances, simplifying container deployments and scaling. # Example: Creating a Fargate task definition aws ecs register-task-definition --family MyTaskDefinition --network-mode awsvpc --container-definitions '[{\"name\":\"MyContainer\",\"image\":\"my-image\",\"memory\":512,\"cpu\":256}]' . | Amazon Lightsail: Provides an easy-to-use VPS (Virtual Private Server) option with a simplified management interface. Lightsail is ideal for simple applications and provides a straightforward way to launch and manage virtual machines. # Example: Creating a Lightsail instance aws lightsail create-instances --instance-names MyInstance --availability-zone us-east-1a --blueprint-id amazon_linux_2 --bundle-id micro_2_0 . | . These services cover a broad spectrum of compute needs, from traditional VMs to modern container and serverless architectures, catering to different application requirements and deployment preferences. No script field found. Date Added: 13 August 2024 . Domain 2: Data Store Management . Question . A company has multiple data sources stored in different formats on Amazon S3. They want to enable their data analysts to easily discover and access these datasets for analysis. The company needs an efficient way to catalog this data and make it searchable. Which AWS service should the company use to automate the creation of a data catalog that makes their datasets in Amazon S3 easily discoverable for analysis? Answer . Implement an AWS Glue Crawler to scan the data in S3 and automatically populate the AWS Glue Data Catalog. AWS Glue Crawler is the most suitable solution for this scenario. It automatically scans data in Amazon S3 and other data stores, infers schemas, and creates metadata tables in the AWS Glue Data Catalog. This enables data analysts to easily discover and access various datasets for analysis. Glue Crawlers can handle multiple data formats and automatically keep the catalog updated with changes in the data structure, reducing the need for manual intervention. No script field found. Date Added: 13 August 2024 . Python . Write a Python function to check whether a given number is prime or not. Question . Write a Python function to check whether a given number is prime or not. Answer . To determine if a given number is prime, we can create a Python function that checks for factors of the number. A prime number is only divisible by 1 and itself, so the function will need to test divisibility up to the square root of the number for efficiency. Script . import math def is_prime(n): \"\"\"Check if a given number n is prime.\"\"\" if n &lt;= 1: return False if n &lt;= 3: return True if n % 2 == 0 or n % 3 == 0: return False i = 5 while i * i &lt;= n: if n % i == 0 or n % (i + 2) == 0: return False i += 6 return True # Example usage: print(is_prime(29)) # Output: True print(is_prime(18)) # Output: False . Date Added: 03 August 2024 . Web . What technologies can be used to apply consistent styles and formats to different parts of a web page? . Question . What technologies can be used to apply consistent styles and formats to different parts of a web page? Answer . To apply consistent styles and formats to different parts of a web page, several technologies and practices can be employed. Here are some of the key technologies used for this purpose: . | CSS (Cascading Style Sheets): The fundamental technology for styling web pages. CSS allows you to define styles for HTML elements, including colors, fonts, layouts, and responsive design. CSS can be applied in several ways: . | External Stylesheets: Linking to a separate CSS file for consistent styling across multiple pages. &lt;link rel=\"stylesheet\" href=\"styles.css\"&gt; . | Internal Styles: Defining CSS rules within a &lt;style&gt; tag in the HTML document‚Äôs &lt;head&gt;. &lt;style&gt; body { font-family: Arial, sans-serif; } &lt;/style&gt; . | Inline Styles: Applying CSS directly to HTML elements using the style attribute, though this method is less common for consistent styling. &lt;div style=\"color: blue;\"&gt;Hello, World!&lt;/div&gt; . | . | CSS Preprocessors: Tools like Sass and Less extend CSS with features such as variables, nesting, and mixins, which enhance maintainability and consistency. | Sass Example: $primary-color: #333; body { color: $primary-color; } . | . | CSS Frameworks: Libraries that provide pre-defined styles and components to help achieve consistent design quickly. Popular frameworks include: . | Bootstrap: Offers a wide range of responsive, mobile-first design components and utilities. &lt;link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\"&gt; . | Foundation: Provides a responsive grid system and various UI components for building consistent layouts. &lt;link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/foundation/6.5.3/css/foundation.min.css\"&gt; . | . | CSS-in-JS Libraries: Techniques that allow you to write CSS directly within JavaScript files, providing scoped styling and dynamic styles. Examples include: . | Styled Components: Allows you to use ES6 and CSS to style components. import styled from 'styled-components'; const Button = styled.button` background: blue; color: white; `; . | Emotion: Provides powerful and flexible styling solutions for React applications. /** @jsxImportSource @emotion/react */ import { css } from '@emotion/react'; const style = css` color: hotpink; `; . | . | CSS Variables: Custom properties that allow you to define reusable values and apply them throughout your stylesheets. :root { --main-bg-color: lightgray; } body { background-color: var(--main-bg-color); } . | Design Systems: Comprehensive frameworks and guidelines that provide a consistent approach to design and development. Examples include: . | Material Design: Google‚Äôs design system offering guidelines and components for consistent UI/UX. | IBM Carbon Design System: Provides design principles, components, and patterns for a cohesive user experience. | . | . These technologies and methodologies help ensure a unified look and feel across your web pages, enhancing both usability and aesthetic appeal. No script field found. Date Added: 02 August 2024 . Testing . What sorts of tests do you consider when building an application? What testing libraries have you used? . Question . What sorts of tests do you consider when building an application? What testing libraries have you used? Answer . When building an application, a comprehensive testing strategy is essential to ensure the software is reliable, performant, and free of defects. Here are the key types of tests to consider: . | Unit Tests: These tests verify that individual components or functions of the application work as expected. They focus on small, isolated pieces of code and are usually written by developers during the coding phase. | Library Used: pytest is a popular library for writing unit tests in Python. It supports fixtures, parameterized testing, and has a simple syntax. import pytest def add(x, y): return x + y def test_add(): assert add(1, 2) == 3 . | . | Integration Tests: These tests check the interaction between different components or systems to ensure they work together correctly. They often involve testing multiple components or services that interact with each other. | Library Used: pytest can also be used for integration tests. pyunit (unittest) is another option for writing integration tests in Python. import unittest class TestIntegration(unittest.TestCase): def test_service_integration(self): # Integration test code self.assertTrue(True) . | . | Functional Tests: These tests evaluate specific features or functionalities of the application from an end-user perspective. They ensure that the application behaves as expected when specific features are used. | Library Used: behave and cucumber are popular libraries for behavior-driven development (BDD), allowing you to write tests in a natural language format. Feature: Showing off behave Scenario: run a simple test Given we have behave installed When we implement a test Then behave should test it for us! . | . | End-to-End (E2E) Tests: These tests simulate real user scenarios to validate that the application works end-to-end. They test the complete flow of the application from the user interface to the backend. | Library Used: Selenium and Cypress are widely used for E2E testing. Selenium allows for browser automation and testing across multiple browsers, while Cypress is known for its fast and reliable testing capabilities with a focus on modern web applications. // Example with Cypress describe('My First Test', () =&gt; { it('Visits the app', () =&gt; { cy.visit('https://example.com') cy.contains('Welcome') }) }) . | . | Performance Tests: These tests evaluate how the application performs under various conditions, such as high load or stress. They help identify performance bottlenecks and ensure the application can handle expected traffic. | Library Used: While performance testing libraries are often separate, integrating performance testing with your existing suite can involve using tools like Locust or JMeter in conjunction with your application code. | . | Security Tests: These tests identify vulnerabilities and ensure that the application is secure from potential attacks. They are crucial for protecting sensitive data and maintaining user trust. | Library Used: Security testing is usually done with specialized tools like OWASP ZAP or Burp Suite. These tools help in performing security assessments and vulnerability scanning. | . | Regression Tests: These tests are performed to ensure that new code changes have not adversely affected existing functionality. They are typically automated and run frequently during the development cycle. | Library Used: pytest and Selenium can be used to automate regression tests, ensuring that previously fixed issues do not reoccur. | . | . A robust testing strategy typically involves a combination of these types of tests and tools to ensure comprehensive coverage and high-quality software. No script field found. Date Added: 02 August 2024 . SDLC . What are the steps to be performed during code review? . Question . What are the steps to be performed during code review? Answer . Code reviews are a critical part of the software development process. They ensure code quality, maintainability, and adherence to best practices. Here are the key steps to perform during a code review: . | Preparation: . | Understand the Context: Familiarize yourself with the purpose and scope of the code being reviewed. Read any related documentation or issue descriptions. | Setup: Ensure you have the necessary access to the codebase, related repositories, and tools needed for the review. | . | Review the Code: . | Readability: Check if the code is easy to read and understand. Look for clear naming conventions, appropriate comments, and logical organization. | Functionality: Verify that the code functions as intended. Ensure it solves the problem or implements the feature correctly. | Style and Conventions: Ensure the code adheres to coding standards and style guidelines set by the team or organization. | Efficiency: Evaluate the performance and efficiency of the code. Look for unnecessary complexity or redundant operations. | Error Handling: Check if the code handles errors and edge cases properly. Look for robust error handling and logging. | Security: Assess the code for potential security vulnerabilities or weaknesses. | . | Testing: . | Unit Tests: Verify that adequate unit tests are included and that they cover various cases. Ensure that tests pass and are effective in catching potential issues. | Integration Tests: Check if integration tests are in place to ensure that the new code interacts correctly with other components. | . | Feedback and Discussion: . | Provide Constructive Feedback: Share your observations and suggestions in a constructive manner. Be specific about issues and provide recommendations for improvement. | Discuss: Engage in discussions with the author and other reviewers to clarify doubts and make collaborative decisions. | . | Approval and Merge: . | Final Review: Conduct a final review to ensure all feedback has been addressed and changes are satisfactory. | Approve: Approve the changes if they meet the required standards and criteria. | Merge: Merge the code into the main branch or repository following the team‚Äôs merging procedures. | . | Post-Review: . | Document Learnings: Document any key learnings or insights from the review to improve future practices. | Reflect: Reflect on the review process and identify areas for improvement in the code review process itself. | . | . Effective code reviews help in maintaining high-quality code and fostering a collaborative development environment. No script field found. Date Added: 02 August 2024 . How do you make a method private in Python? . Question . How do you make a method private in Python? Answer . In Python, methods can be made private by using a naming convention. Python does not have true private methods as seen in some other programming languages, but it follows a convention that can help achieve encapsulation: . | Single Underscore (_prefix): Prefixing a method name with a single underscore (e.g., _method_name) indicates that it is intended for internal use. This is a convention that suggests the method is private, but it can still be accessed from outside the class if needed. For example: class MyClass: def _private_method(self): print(\"This is a private method\") . | Double Underscore (__prefix): Prefixing a method name with double underscores (e.g., __method_name) invokes name mangling. This changes the method name internally to include the class name, making it harder to access from outside the class. This approach is stronger in terms of hiding the method, but it is still not completely foolproof. For example: class MyClass: def __private_method(self): print(\"This is a more private method\") obj = MyClass() obj.__private_method() # This will raise an AttributeError . | . Both conventions help in managing access to methods and are part of Python‚Äôs flexible approach to encapsulation. The choice between a single or double underscore depends on the level of access restriction required. No script field found. Date Added: 02 August 2024 . What frameworks and libraries have you used for application development using Python? . Question . Can you provide some examples from your CV? Answer . I have used several frameworks and libraries for application development in Python across various projects: . | Pandas: Utilized for data manipulation and analysis, essential in building analytics and insights frameworks for financial markets and multi-asset portfolios. | NumPy: Employed for numerical operations and handling large datasets efficiently, particularly in quantitative and financial modeling. | Dask: Applied for parallel computing to manage and process large datasets, enhancing performance in data-intensive applications. | FastAPI: Leveraged to develop high-performance web APIs and microservices, particularly in building modular APIs for data integrations and analytics platforms. | Flask: Used for creating lightweight web applications, especially in prototyping and rapid development scenarios. | SQLAlchemy: Integrated as an ORM for seamless interaction with databases, used in data products and ETL pipelines. | Apache Airflow: Employed for orchestrating ETL pipelines and managing complex workflows in cloud-native data processing environments. | PySpark: Utilized for processing large datasets on Hadoop, improving data handling and analytics capabilities in financial and data engineering projects. | Beautiful Soup: Used for web scraping to gather financial and market data efficiently. | Scrapy: Applied for creating robust and scalable web crawlers to extract and process data from various sources. These tools have been integral to my roles in data engineering, financial modeling, and application development, enabling efficient data handling, scalable application design, and effective data integration solutions. | . No script field found. Date Added: 02 August 2024 . Have you done significant application development using Python? . Question . Can you provide some examples from your CV? Answer . Yes, I have done significant application development using Python. Here are a few examples from my CV: . | Project: Serverless Data Pipelines: Implemented cloud-native ETL pipelines and a Data Analytics and Insights platform using Python on AWS. Utilized libraries like Pandas and SQL Alchemy for data processing. | Project: Python Web Scrapers: Developed Python web scrapers for efficient data extraction and ingestion in various projects, including financial market data. | Project: Analytics and Insights: Built an analytics and insights framework using Pythonic functions for financial markets and multi-asset portfolios. | . No script field found. Date Added: 02 August 2024 . Design Patterns . What are the benefits of using SOLID principles and what does the acronym SOLID stand for? . Question . What are the benefits of using SOLID principles and what does the acronym SOLID stand for? Answer . The SOLID principles are a set of design principles that help developers create more understandable, flexible, and maintainable software. Each principle aims to address common problems in software design and improve the overall quality of code. The acronym SOLID stands for: . | S - Single Responsibility Principle (SRP): . | Definition: A class should have only one reason to change, meaning it should have only one job or responsibility. | Benefits: Simplifies the design by making each class responsible for a single part of the functionality, which enhances readability and reduces the risk of changes in one area affecting others. | . | O - Open/Closed Principle (OCP): . | Definition: Software entities (classes, modules, functions, etc.) should be open for extension but closed for modification. | Benefits: Allows a system to be extended with new functionality without altering existing code, which reduces the risk of introducing bugs and makes the system more robust and adaptable to change. | . | L - Liskov Substitution Principle (LSP): . | Definition: Objects of a superclass should be replaceable with objects of a subclass without affecting the correctness of the program. | Benefits: Ensures that subclasses properly extend the functionality of their parent classes without changing expected behavior, leading to more reliable and predictable code. | . | I - Interface Segregation Principle (ISP): . | Definition: Clients should not be forced to depend on interfaces they do not use. Interfaces should be client-specific rather than general-purpose. | Benefits: Encourages the design of smaller, more specific interfaces, which makes the system easier to understand and changes easier to implement without affecting unrelated parts of the system. | . | D - Dependency Inversion Principle (DIP): . | Definition: High-level modules should not depend on low-level modules. Both should depend on abstractions (e.g., interfaces). Abstractions should not depend on details; details should depend on abstractions. | Benefits: Promotes loose coupling between high-level and low-level modules, making the system more modular and easier to manage and extend. It enhances flexibility and improves the system‚Äôs ability to adapt to change. | . | . Benefits of Using SOLID Principles: - Improved Code Maintainability: By following SOLID principles, code becomes easier to maintain and extend, reducing the time and cost associated with changes and bug fixes. | Enhanced Readability: SOLID principles promote writing clear and understandable code, which makes it easier for developers to read and understand the codebase. | Increased Flexibility: SOLID principles help in creating systems that are easier to adapt to new requirements and changes, making the codebase more flexible. | Reduced Risk of Bugs: By adhering to SOLID principles, developers can avoid common pitfalls and design issues that often lead to bugs and inconsistencies in the software. | . No script field found. Date Added: 02 August 2024 . Can you name a few design patterns? . Question . Can you name a few design patterns? Answer . Design patterns are common solutions to recurring problems in software design. They provide templates for solving common design issues and improving code maintainability. Here are a few widely recognized design patterns: . | Singleton Pattern: . | Purpose: Ensures a class has only one instance and provides a global point of access to it. | Usage: Often used for managing shared resources such as configuration settings or connection pools. | . | Factory Method Pattern: . | Purpose: Defines an interface for creating objects but allows subclasses to alter the type of objects that will be created. | Usage: Useful for creating objects in a super class but allowing subclasses to modify the type of created objects. | . | Observer Pattern: . | Purpose: Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. | Usage: Commonly used in event handling systems, such as in GUI frameworks or message broadcasting systems. | . | Decorator Pattern: . | Purpose: Allows behavior to be added to individual objects, either statically or dynamically, without affecting the behavior of other objects from the same class. | Usage: Useful for adding responsibilities to objects at runtime, like adding new features to a window in a graphical user interface. | . | Strategy Pattern: . | Purpose: Defines a family of algorithms, encapsulates each one, and makes them interchangeable. Strategy lets the algorithm vary independently from clients that use it. | Usage: Ideal for scenarios where multiple algorithms can be used interchangeably, such as different sorting or compression strategies. | . | Adapter Pattern: . | Purpose: Allows the interface of an existing class to be used as another interface. It acts as a bridge between two incompatible interfaces. | Usage: Often used to integrate new features with legacy systems or to make different APIs compatible with one another. | . | Command Pattern: . | Purpose: Encapsulates a request as an object, thereby allowing for parameterization of clients with queues, requests, and operations. | Usage: Useful for implementing undo/redo functionality, queuing operations, or logging operations. | . | Facade Pattern: . | Purpose: Provides a simplified interface to a complex subsystem. It defines a higher-level interface that makes the subsystem easier to use. | Usage: Commonly used to provide a simplified interface to a large body of code, such as a complex library or framework. | . | . These design patterns help in creating scalable, maintainable, and flexible codebases by addressing common design issues and providing standardized solutions. No script field found. Date Added: 02 August 2024 . | Made with ‚ù§Ô∏è by Abrar Mudhir &copy; 2024 &gt; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; &#8287;&#8287; . ",
    "url": "/qanda/#q--a-%EF%B8%8F",
    
    "relUrl": "/qanda/#q--a-Ô∏è"
  },"16": {
    "doc": "üó£Ô∏è Q & A",
    "title": "üó£Ô∏è Q & A",
    "content": "| ",
    "url": "/qanda/",
    
    "relUrl": "/qanda/"
  }
}
